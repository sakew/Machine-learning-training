{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron for classifying binary response variable\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets # imports datasets from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "x = cancer['data']\n",
    "y = cancer['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = Perceptron(random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .25, random_state=25) #25% hold out for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=40, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = per.predict(x_test) # predict benign and malignant tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 32],\n",
       "       [ 0, 93]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7762237762237763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks Multi-Layer-Perceptrons(MLP) for binary classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cancer['data']\n",
    "y = cancer['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # binary response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.25, random_state=25) #25% hold out for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(x_train)\n",
    "# now apply the transformations to the data\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test) # scale the input (independent) and output (dependent) variables to [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(x_test) # predict benign and malignant tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45,  5],\n",
       "       [ 2, 91]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural Network (MLP) for multi-class classification\n",
    "glass=pd.read_csv(\"glassClass.csv\")\n",
    "glass.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=glass.drop(\"Type\", axis=1) #predictors\n",
    "y=glass[\"Type\"] #response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.25, random_state=25) #25% hold out for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=mlp.predict(x_test) # predict glass classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  5,  1,  0,  0,  0],\n",
       "       [ 3, 18,  2,  0,  0,  0],\n",
       "       [ 1,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  2,  1],\n",
       "       [ 1,  0,  0,  0,  0,  7]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumostize MLP\n",
    "mlp2 = MLPClassifier(activation = 'logistic', solver='lbfgs', alpha = 0.0001, random_state = 1) # specify activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp2.predict(x_test) #predict glass classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  1,  2,  0,  0,  0],\n",
       "       [ 4, 15,  2,  2,  0,  0],\n",
       "       [ 1,  0,  1,  0,  0,  0],\n",
       "       [ 0,  1,  0,  1,  0,  0],\n",
       "       [ 0,  1,  0,  0,  2,  0],\n",
       "       [ 0,  1,  0,  0,  0,  7]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3=MLPClassifier(activation='logistic', solver='adam', hidden_layer_sizes=(200,25), alpha=0.0001, random_state=1,\n",
    "                  max_iter=300) # specify activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 25), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp3.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "data = datasets.load_boston() # Load Boston dataset from datasets library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data/predictors as the pre-set feature names\n",
    "x = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "# Put the target (housing value -- MEDV) in another DataFrame\n",
    "y = pd.DataFrame(data.target, columns=[\"MEDV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.25,random_state=25) #25% hold out for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = MLPRegressor(activation = 'logistic', solver='lbfgs', alpha = 0.0001, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlr.predict(x_test) #predict house prices\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4991516328331419\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.78689613527967"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the hidden layer\n",
    "clf = MLPRegressor(hidden_layer_sizes=(15,), max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test) #predict house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.58283506111364"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6699511354973284\n"
     ]
    }
   ],
   "source": [
    "print r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Classifier on a real dataset\n",
    "#42k rows and 700+ columns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "data=pd.read_csv(\"Digits1.csv\") #classify digits on basis of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(\"label\", axis=1) #predictors\n",
    "y=data[\"label\"] #response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.25, random_state=25) #25% hold out for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64 were all converted to float64 by the scale function.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "E:\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by the scale function.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# deriving PCs from the predictor / x variables\n",
    "#scaling the values\n",
    "x_train=scale(x_train)\n",
    "x_test=scale(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=80) #given the large number of predictors, derive 80 pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05791199, 0.04159204, 0.03839578, 0.02977874, 0.02611457,\n",
       "       0.02262106, 0.01980964, 0.01796008, 0.01581079, 0.01438001,\n",
       "       0.01385406, 0.01241771, 0.01149768, 0.01136659, 0.01068979,\n",
       "       0.01033662, 0.00957253, 0.00946681, 0.00919453, 0.00900037,\n",
       "       0.00858623, 0.00830432, 0.00785756, 0.00766566, 0.00738388,\n",
       "       0.0070562 , 0.00699957, 0.00678626, 0.00642034, 0.00622572,\n",
       "       0.00617657, 0.00603687, 0.00587035, 0.00581877, 0.00574258,\n",
       "       0.00556856, 0.00549117, 0.00533912, 0.00517723, 0.00500506,\n",
       "       0.00493839, 0.00487663, 0.00476821, 0.00470327, 0.00457053,\n",
       "       0.00453339, 0.00450413, 0.00442484, 0.00436825, 0.00424837,\n",
       "       0.0041175 , 0.00407721, 0.00402054, 0.00399591, 0.0038714 ,\n",
       "       0.00383857, 0.00378171, 0.00371194, 0.00361769, 0.00360096,\n",
       "       0.0035384 , 0.00347809, 0.00347639, 0.00337743, 0.00330752,\n",
       "       0.00327369, 0.00322583, 0.00317664, 0.00316186, 0.00309552,\n",
       "       0.00306739, 0.00300005, 0.00298381, 0.00293188, 0.00289015,\n",
       "       0.00285499, 0.00281887, 0.00281556, 0.00277862, 0.00273938])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The amount of variance that each PC explains\n",
    "var = xp.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16d575f8>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 45 pcs explain the maximum variance in the dataset\n",
    "# fit a new PCA and store results along with labels in a data frame\n",
    "pca = PCA(n_components=45) # use first 3 PCs(update to 100 later)\n",
    "pca.fit(x_train)\n",
    "PCtrain = pd.DataFrame(pca.transform(x_train))\n",
    "PCtrain['label'] = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCtest = pd.DataFrame(pca.transform(x_test)) #testing\n",
    "PCtest['label'] = data['label']\n",
    "# get x and y from our PCA transformed dataframe\n",
    "# y1 = PCtrain['label'][0:20000]\n",
    "# x1 = PCtrain.drop('label',axis=1)[0:20000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(activation = 'logistic', solver='lbfgs', hidden_layer_sizes=(3000,), alpha=0.0001, random_state=1)\n",
    "#specify activation function\n",
    "#clf.fit(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = PCtrain['label']\n",
    "x2=PCtrain.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(3000,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = PCtest['label']\n",
    "x3 = PCtest.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 49, 369,  80, 122,  72,  19,  30, 175,  18, 102],\n",
       "       [ 68, 367,  96, 131,  86,  22,  31, 215,  27, 116],\n",
       "       [ 66, 363,  86, 121,  71,  23,  49, 187,  19, 104],\n",
       "       [ 53, 374,  79,  98,  72,  20,  37, 195,  27, 102],\n",
       "       [ 58, 353,  74, 113,  88,  17,  38, 169,  16,  90],\n",
       "       [ 56, 307, 101, 117,  63,  28,  35, 136,  19,  97],\n",
       "       [ 49, 371, 107, 123,  74,  12,  21, 180,  20, 100],\n",
       "       [ 56, 372,  90, 125,  74,  20,  25, 191,  30, 114],\n",
       "       [ 54, 336,  82, 107,  61,  18,  33, 177,  24, 102],\n",
       "       [ 54, 369,  83, 126,  60,  16,  31, 178,  22,  97]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y3, y_pred)\n",
    "confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
